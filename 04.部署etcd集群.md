<!-- toc -->

tags: etcd

# 04.部署 etcd 集群

etcd 是基于 Raft 的分布式 key-value 存储系统，由 CoreOS 开发，常用于服务发现、共享配置以及并发控制（如 leader 选举、分布式锁等）。kubernetes 使用 etcd 存储所有运行数据。

本文档介绍部署一个三节点高可用 etcd 集群的步骤：

+ 下载和分发 etcd 二进制文件；
+ 创建 etcd 集群各节点的 x509 证书，用于加密客户端(如 etcdctl) 与 etcd 集群、etcd 集群之间的数据流；
+ 创建 etcd 的 systemd unit 文件，配置服务参数；
+ 检查集群工作状态。

etcd 集群各节点的名称和 IP 如下：
k8s-node01：192.168.99.101
k8s-node02：192.168.99.102
k8s-node03：192.168.99.103

## 下载和分发 etcd 二进制文件

到 [https://github.com/etcd-io/etcd/releases](https://github.com/etcd-io/etcd/releases) 页面下载最新版本的发布包：

``` bash
[admin@k8s-admin ~]$ wget https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-amd64.tar.gz
[admin@k8s-admin ~]$ tar -zxf etcd-v3.3.12-linux-amd64.tar.gz
```

分发二进制文件到集群所有节点：

``` bash
[admin@k8s-admin ~]$ ansible k8s-masters -m copy -a "src=etcd-v3.3.12-linux-amd64/etcd dest=/usr/local/bin/ mode=a+x"
[admin@k8s-admin ~]$ ansible k8s-masters -m copy -a "src=etcd-v3.3.12-linux-amd64/etcdctl dest=/usr/local/bin/ mode=a+x"
[admin@k8s-admin ~]$ chmod a+x etcd-v3.3.12-linux-amd64/{etcd,etcdctl}
[admin@k8s-admin ~]$ sudo cp etcd-v3.3.12-linux-amd64/{etcd,etcdctl} /usr/local/bin/
```

## 创建 etcd 证书和私钥

创建证书签名请求：

``` bash
[admin@k8s-admin ~]$ cat >cert/etcd-csr.json <<EOF
{
    "CN": "etcd",
    "hosts": [
        "127.0.0.1",
        "192.168.99.101",
        "192.168.99.102",
        "192.168.99.103"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "ST": "Jiangsu",
            "L": "Suzhou",
            "O": "k8s",
            "OU": "wangxyd"
        }
    ]
}
EOF
```
+ hosts 字段指定授权使用该证书的 etcd 节点 IP 或域名列表，这里将 etcd 集群的三个节点 IP 都列在其中；

生成证书和私钥：

``` bash
[admin@k8s-admin ~]$ cfssl gencert \
    -ca=cert/ca.pem \
    -ca-key=cert/ca-key.pem \
    -config=cert/ca-config.json \
    -profile=kubernetes \
    cert/etcd-csr.json | cfssljson -bare cert/etcd
[admin@k8s-admin ~]$ ls cert/etcd*
cert/etcd.csr  cert/etcd-csr.json  cert/etcd-key.pem  cert/etcd.pem
```

分发生成的证书和私钥到各 etcd 节点：

``` bash
[admin@k8s-admin ~]$ ansible k8s-masters -m copy -a "src=cert/etcd.pem dest=/etc/etcd/cert/"
[admin@k8s-admin ~]$ ansible k8s-masters -m copy -a "src=cert/etcd-key.pem dest=/etc/etcd/cert/"
```

## 创建 etcd 的 systemd unit 模板文件

``` bash
[admin@k8s-admin ~]$ mkdir systemd
[admin@k8s-admin ~]$ cat >systemd/etcd.service.j2 <<"EOF"
[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target
Documentation=https://github.com/coreos

[Service]
Type=notify
WorkingDirectory={{ ETCD_DATA_DIR }}
EnvironmentFile=/etc/etcd/etcd.conf
ExecStart=/usr/local/bin/etcd $ETCD_ARGS
Restart=on-failure
RestartSec=5
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
EOF
[admin@k8s-admin ~]$
[admin@k8s-admin ~]$ cat >systemd/etcd.conf.j2 <<"EOF"
ETCD_ARGS=" \
  --data-dir={{ ETCD_DATA_DIR }} \
  --wal-dir={{ ETCD_WAL_DIR }} \
  --name={{ ansible_host }} \
  --client-cert-auth \
  --cert-file=/etc/etcd/cert/etcd.pem \
  --key-file=/etc/etcd/cert/etcd-key.pem \
  --trusted-ca-file=/etc/kubernetes/cert/ca.pem \
  --peer-client-cert-auth \
  --peer-cert-file=/etc/etcd/cert/etcd.pem \
  --peer-key-file=/etc/etcd/cert/etcd-key.pem \
  --peer-trusted-ca-file=/etc/kubernetes/cert/ca.pem \
  --listen-peer-urls=https://{{ ansible_eth0.ipv4.address }}:2380 \
  --initial-advertise-peer-urls=https://{{ ansible_eth0.ipv4.address }}:2380 \
  --listen-client-urls=https://{{ ansible_eth0.ipv4.address }}:2379,http://127.0.0.1:2379 \
  --advertise-client-urls=https://{{ ansible_eth0.ipv4.address }}:2379 \
  --initial-cluster-token=etcd-cluster \
  --initial-cluster={{ ETCD_NODES }} \
  --initial-cluster-state=new \
  --auto-compaction-mode=periodic \
  --auto-compaction-retention=1 \
  --max-request-bytes=33554432 \
  --quota-backend-bytes=6442450944 \
  --heartbeat-interval=250 \
  --election-timeout=2000 "
EOF
```
+ `WorkingDirectory`、`--data-dir`：指定工作目录和数据目录为 `${ETCD_DATA_DIR}`，需在启动服务前创建这个目录；
+ `--wal-dir`：指定 wal 目录，为了提高性能，一般使用 SSD 或者和 `--data-dir` 不同的磁盘；
+ `--name`：指定etcd节点名称，这里使用主机名作为节点名（非必需）。当 `--initial-cluster-state` 值为 `new` 时，`--name` 的参数值必须位于 `--initial-cluster` 列表中；
+ `--cert-file`、`--key-file`：etcd server 与 client 通信时使用的证书和私钥；
+ `--trusted-ca-file`：签名 client 证书的 CA 证书，用于验证 client 证书；
+ `--peer-cert-file`、`--peer-key-file`：etcd 与 peer 通信使用的证书和私钥；
+ `--peer-trusted-ca-file`：签名 peer 证书的 CA 证书，用于验证 peer 证书；
+ `--listen-client-urls` and `--listen-peer-urls` specify the local addresses etcd server binds to for accepting incoming connections. To listen on a port for all interfaces, specify `0.0.0.0` as the listen IP address.
+ `--advertise-client-urls` and `--initial-advertise-peer-urls` specify the addresses etcd clients or other etcd members should use to contact the etcd server. The advertise addresses must be reachable from the remote machines. Do not advertise addresses like `localhost` or `0.0.0.0` for a production setup since these addresses are unreachable from remote machines.
+ `--initial-cluster`：初始集群成员列表，由所有 `--initial-cluster-state` 值为 `new` 的etcd节点的 `--name` 和 `--initial-advertise-peer-urls` 指定的值组成；
+ `--initial-cluster-token`：集群的名字。

参考：
etcd Clustering Guide：https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/clustering.md

## 为各节点创建和分发 etcd systemd unit 文件
``` bash
[admin@k8s-admin ~]$ cat >systemd/etcd.service.yaml <<"EOF"
- hosts: k8s-masters
  remote_user: root
  tasks:
  - name: copy etcd.service
    template:
      src: etcd.service.j2
      dest: /usr/lib/systemd/system/etcd.service  
  - name: copy etcd.conf
    template:
      src: etcd.conf.j2
      dest: /etc/etcd/etcd.conf
  - name: create the data directory for etcd
    file:
      path: "{{ ETCD_DATA_DIR }}"
      state: directory
  - name: create the wal directory for etcd
    file:
      path: "{{ ETCD_WAL_DIR }}"
      state: directory
  - name: enable and start etcd.service
    systemd:
      name: etcd
      state: restarted
      enabled: yes
      daemon_reload: yes
EOF

[admin@k8s-admin ~]$ ansible-playbook systemd/etcd.service.yaml
[admin@k8s-admin ~]$ ansible k8s-masters -m shell -a "systemctl status etcd.service|grep -e Loaded -e Active"
```
+ 确保状态为“active (running)”并且“enabled”。


## 检查端口监听情况
``` bash
[root@k8s-node01 ~]# ss -lnptu|grep 2379
tcp    LISTEN    0    128    192.168.99.101:2379    *:*    users:(("etcd",pid=27228,fd=7))
tcp    LISTEN    0    128    127.0.0.1:2379         *:*    users:(("etcd",pid=27228,fd=6))
[root@k8s-node01 ~]# ss -lnptu|grep 2380
tcp    LISTEN    0    128    192.168.99.101:2380    *:*    users:(("etcd",pid=27228,fd=5))
```
+ 外部客户端（etcdctl、kube-apiserver）使用 `tcp/2379` ，由 `--listen-client-urls` 和 `--advertise-client-urls` 指定；
+ etcd 集群内部各成员之间使用 `tcp/2380` ，由 `--listen-peer-urls` 和 `--initial-advertise-peer-urls` 指定。

## 验证服务状态
首先设置环境变量 `ETCDCTL_API=3`，使用v3版本的API（默认v2），然后执行如下命令：
``` bash
[admin@k8s-admin ~]$ source environment.sh
[admin@k8s-admin ~]$ export ETCDCTL_API=3
[admin@k8s-admin ~]$ etcdctl \
  --endpoints=$ETCD_ENDPOINTS \
  --cacert=cert/ca.pem \
  --cert=cert/etcd.pem \
  --key=cert/etcd-key.pem \
  endpoint health
https://192.168.99.101:2379 is healthy: successfully committed proposal: took = 2.411233ms
https://192.168.99.103:2379 is healthy: successfully committed proposal: took = 2.106341ms
https://192.168.99.102:2379 is healthy: successfully committed proposal: took = 2.892882ms
```
+ 输出均为 `healthy` 时表示集群服务正常。

## 查看当前的 leader

``` bash
[admin@k8s-admin ~]$ etcdctl \
  --endpoints=$ETCD_ENDPOINTS \
  --cacert=cert/ca.pem \
  --cert=cert/etcd.pem \
  --key=cert/etcd-key.pem \
  endpoint status -w table
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
|          ENDPOINT           |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
| https://192.168.99.101:2379 | d0a9ad34152bf48f |  3.3.12 |   20 kB |     false |         2 |          8 |
| https://192.168.99.102:2379 | 3158a480920ae582 |  3.3.12 |   20 kB |     false |         2 |          8 |
| https://192.168.99.103:2379 | 9e9c23acaad2c0cd |  3.3.12 |   20 kB |      true |         2 |          8 |
+-----------------------------+------------------+---------+---------+-----------+-----------+------------+
```
+ 可见，当前的 leader 为 k8s-node03(192.168.99.103)。

## 查看当前 etcd 存储的数据
``` bash
[admin@k8s-admin ~]$ etcdctl \
  --endpoints=$ETCD_ENDPOINTS \
  --cacert=cert/ca.pem \
  --cert=cert/etcd.pem \
  --key=cert/etcd-key.pem \
  get / --prefix=true
```
+ 可见当前etcd集群没有存储任何数据。
