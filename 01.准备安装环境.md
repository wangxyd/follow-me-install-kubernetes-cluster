<!-- toc -->

tags: environment

# 01.准备安装环境

## 集群机器列表

这里总共使用了6台虚拟机，主机名、IP地址和用途如下：

主机名|IP地址|节点类型
---|---|---
k8s-node01|192.168.99.101|etcd集群节点，master节点，worker点
k8s-node02|192.168.99.102|etcd集群节点，master节点，worker点
k8s-node03|192.168.99.103|etcd集群节点，master节点，worker点
k8s-node04|192.168.99.104|worker点
k8s-node05|192.168.99.105|worker点
k8s-admin| 192.168.99.251|Ansible管理主机

## 配置主机名和网络

配置所有虚拟机的主机名和IP地址，以k8s-node01为例：
``` bash
# hostnamectl set-hostname k8s-node01
# nmcli con add con-name nat-static ifname eth0 ipv4.addresses 192.168.99.101/24 ipv4.gateway 192.168.99.1 ipv4.dns 192.168.99.1 ipv4.method manual type ethernet
# nmcli con up nat-static
```

## 配置Ansible管理主机
### 安装Ansible
``` bash
[admin@k8s-admin ~]$ git clone git://github.com/ansible/ansible.git --recursive
[admin@k8s-admin ~]$ sudo yum install python-setuptools -y
[admin@k8s-admin ~]$ sudo easy_install pip
[admin@k8s-admin ~]$ sudo pip install -r ansible/requirements.txt
[admin@k8s-admin ~]$ echo "export PATH=\$PATH:$PWD/ansible/bin" >> ~/.bash_profile
[admin@k8s-admin ~]$ echo "source $PWD/ansible/hacking/env-setup -q" >> ~/.bashrc
[admin@k8s-admin ~]$ source .bash_profile
[admin@k8s-admin ~]$ ansible --version
ansible 2.8.0.dev0
  config file = None
  configured module search path = [u'/home/admin/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /home/admin/ansible/lib/ansible
  executable location = /home/admin/ansible/bin/ansible
  python version = 2.7.5 (default, Apr 11 2018, 07:36:10) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)]
```

### 创建主机清单文件
``` bash
[admin@k8s-admin ~]$ sudo mkdir /etc/ansible && sudo vi /etc/ansible/hosts
[k8s-workers:children]
k8s-masters

[k8s-masters]
k8s-node01 ansible_user=root
k8s-node02 ansible_user=root
k8s-node03 ansible_user=root

[k8s-workers]
k8s-node04 ansible_user=root
k8s-node05 ansible_user=root

[k8s-workers:vars]
# 集群各机器 IP 数组
NODE_IPS=(192.168.99.101 192.168.99.102 192.168.99.103 192.168.99.104 192.168.99.105)

# 集群各 IP 对应的 主机名数组
NODE_NAMES=(k8s-node01 k8s-node02 k8s-node03 k8s-node04 k8s-node05)

# etcd 集群服务地址列表
ETCD_ENDPOINTS="https://192.168.99.101:2379,https://192.168.99.102:2379,https://192.168.99.103:2379"

# etcd 集群间通信的 IP 和端口
ETCD_NODES="k8s-node01=https://192.168.99.101:2380,k8s-node02=https://192.168.99.102:2380,k8s-node03=https://192.168.99.103:2380"

# kube-apiserver 的反向代理(kube-nginx)地址端口
KUBE_APISERVER="https://192.168.99.100:8443"

# 节点间互联网络接口名称
IFACE="eth0"

# etcd 数据目录
ETCD_DATA_DIR="/data/etcd/data"

# etcd WAL 目录，建议是 SSD 磁盘分区，或者和 ETCD_DATA_DIR 不同的磁盘分区
ETCD_WAL_DIR="/data/etcd/wal"

# k8s 各组件数据目录
K8S_DIR="/data/kubernetes"

# docker 数据目录
DOCKER_DIR="/data/docker"

## 以下参数一般不需要修改
# TLS Bootstrapping 使用的 Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x | tr -d ' ' 生成
BOOTSTRAP_TOKEN="41f7e4ba8b7be874fcff18bf5cf41a7c"

# 最好使用 当前未用的网段 来定义服务网段和 Pod 网段

# 服务网段，部署前路由不可达，部署后集群内路由可达(kube-proxy 保证)
SERVICE_CIDR="10.0.0.0/16"

# Pod 网段，建议 /16 段地址，部署前路由不可达，部署后集群内路由可达(flanneld 保证)
CLUSTER_CIDR="172.16.0.0/16"

# 服务端口范围 (NodePort Range)
NODE_PORT_RANGE="30000-32767"

# flanneld 网络配置前缀
FLANNEL_ETCD_PREFIX="/kubernetes/network"

# kubernetes 服务 IP (一般是 SERVICE_CIDR 中第一个IP)
CLUSTER_KUBERNETES_SVC_IP="10.16.0.1"

# 集群 DNS 服务 IP (从 SERVICE_CIDR 中预分配)
CLUSTER_DNS_SVC_IP="10.16.0.2"

# 集群 DNS 域名（末尾不带点号）
CLUSTER_DNS_DOMAIN="cluster.local"
```

### 配置Ansible管理主机的hosts文件
``` bash
[admin@k8s-admin ~]$ sudo vi /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.99.100 k8s-apiserver
192.168.99.101 k8s-node01
192.168.99.102 k8s-node02
192.168.99.103 k8s-node03
192.168.99.104 k8s-node04
192.168.99.105 k8s-node05
```

### 配置Ansible管理主机无密码SSH连接被管理的k8s节点
``` bash
[admin@k8s-admin ~]$ ssh-keygen -t rsa -b 4096 -N "" -f ~/.ssh/id_rsa
[admin@k8s-admin ~]$ for i in {1..5};do ssh-copy-id -i ~/.ssh/id_rsa root@k8s-node0$i;done
```
Ansible管理主机配置完成，下面使用Ansible配置被管理的主机（也就是k8s节点）。

## 准备Kubernetes节点主机
### 配置 hosts 文件
``` bash
[admin@k8s-admin ~]$ ansible k8s-workers -m copy -a "src=/etc/hosts dest=/etc/hosts"
```

### 添加 docker 账户

在所有worker节点上添加 docker 账户：
``` bash
[admin@k8s-admin ~]$ ansible all -i localhost, -m debug -a "msg={{'docker' | password_hash('sha512','salt')}}"
localhost | SUCCESS => {
    "msg": "$6$salt$AoGYA6qGGHMiDKeThM/IBfld9FKT5N9aNuZ/.F3CrrWPZV2BMj7fj.evvOB/Uf1zeTQfT4cAzKCThALnGI4gX1"
}
[admin@k8s-admin ~]$ ansible k8s-workers -m user -a "name=docker groups=wheel password='\$6\$salt\$AoGYA6qGGHMiDKeThM/IBfld9FKT5N9aNuZ/.F3CrrWPZV2BMj7fj.evvOB/Uf1zeTQfT4cAzKCThALnGI4gX1'"
```
其中：加密算法就是用明文密码和一个叫salt的东西通过函数crypt()完成加密。
而所谓的密码域密文是由三部分组成的，即：$id$salt$encrypted。
id为1时，采用md5进行加密；id为5时，采用SHA256进行加密；id为6时，采用SHA512进行加密。
注意：密码密文中的“$”符号必须使用转移。

所有节点创建k8s用户，同时添加到wheel和docker组：
``` bash
[admin@k8s-admin ~]$ ansible all -i localhost, -m debug -a "msg={{'k8s' | password_hash('sha512','salt')}}"
localhost | SUCCESS => {
    "msg": "$6$salt$ryC5nnCEcwuyEYAb3ZUAKRnY2UPMgWUYYT1h13QUH4UEWYK4cgcfvuF/On96oSgl/z1lJJ15ASA3ys5mofN4q/"
}
[admin@k8s-admin ~]$ ansible all -m user -a "name=k8s groups=wheel,docker password='\$6\$salt\$ryC5nnCEcwuyEYAb3ZUAKRnY2UPMgWUYYT1h13QUH4UEWYK4cgcfvuF/On96oSgl/z1lJJ15ASA3ys5mofN4q/'"
```

### 安装依赖包

在每台机器上安装依赖包：

CentOS:

``` bash
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    ssh root@${node_ip} "yum install -y epel-release"
    ssh root@${node_ip} "yum install -y conntrack ipvsadm ipset jq iptables curl sysstat libseccomp && /usr/sbin/modprobe ip_vs "
  done
```

Ubuntu:

``` bash
source /opt/k8s/bin/environment.sh
for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    ssh root@${node_ip} "apt-get install -y conntrack ipvsadm ipset jq iptables curl sysstat libseccomp && /usr/sbin/modprobe ip_vs "
  done
```

+ ipvs 依赖 ipset；

### 关闭防火墙

在每台机器上关闭防火墙，清理防火墙规则，设置默认转发策略：

```
[admin@k8s-admin ~]$ ansible all -m systemd -a "name=firewalld state=stopped enabled=no"
[admin@k8s-admin ~]$ ansible all -m shell -a "iptables -F && iptables -X && iptables -F -t nat && iptables -X -t nat && iptables -P FORWARD ACCEPT"
```

### 关闭 swap 分区

如果开启了 swap 分区，kubelet 会启动失败(可以通过将参数 --fail-swap-on 设置为 false 来忽略 swap on)，故需要在每台机器上关闭 swap 分区。同时注释 `/etc/fstab` 中相应的条目，防止开机自动挂载 swap 分区：

```
[admin@k8s-admin ~]$ ansible all -m shell -a "swapoff -a && sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab"
```

### 关闭 SELinux

关闭 SELinux，否则后续 K8S 挂载目录时可能报错 `Permission denied`：

```
[admin@k8s-admin ~]$ ansible all -m shell -a "if [ "$(getenforce)" == "Enforcing" ]; then setenforce 0;fi"
[admin@k8s-admin ~]$ ansible all -m shell -a "sed -i "s/^SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config"
```

### 关闭 dnsmasq（可选）

linux 系统开启了 dnsmasq 后(如 GUI 环境)，将系统 DNS Server 设置为 127.0.0.1，这会导致 docker 容器无法解析域名，需要关闭它：
```
[admin@k8s-admin ~]$ ansible k8s-workers -m systemd -a "name=dnsmasq state=stopped enabled=no"
```

### 加载内核模块

``` bash
sudo modprobe br_netfilter
```

### 优化内核参数

``` bash
cat > kubernetes.conf <<EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
net.ipv4.tcp_tw_recycle=0
vm.swappiness=0 # 禁止使用 swap 空间，只有当系统 OOM 时才允许使用它
vm.overcommit_memory=1 # 不检查物理内存是否够用
vm.panic_on_oom=0 # 开启 OOM
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF
sudo cp kubernetes.conf  /etc/sysctl.d/kubernetes.conf
sudo sysctl -p /etc/sysctl.d/kubernetes.conf
```
+ 必须关闭 tcp_tw_recycle，否则和 NAT 冲突，会导致服务不通；
+ 关闭 IPV6，防止触发 docker BUG；

### 设置系统时区

``` bash
# 调整系统 TimeZone
sudo timedatectl set-timezone Asia/Shanghai

# 将当前的 UTC 时间写入硬件时钟
sudo timedatectl set-local-rtc 0

# 重启依赖于系统时间的服务
sudo systemctl restart rsyslog
sudo systemctl restart crond
```

### 更新系统时间

``` bash
sudo ntpdate cn.pool.ntp.org
```

### 关闭无关的服务

``` bash
sudo systemctl stop postfix && sudo systemctl disable postfix
```

### 设置 rsyslogd 和 systemd journald

systemd 的 journald 是 Centos 7 缺省的日志记录工具，它记录了所有系统、内核、Service Unit 的日志。

相比 systemd，journald 记录的日志有如下优势：

1. 可以记录到内存或文件系统；(默认记录到内存，对应的位置为 /run/log/jounal)
1. 可以限制占用的磁盘空间、保证磁盘剩余空间；
1. 可以限制日志文件大小、保存的时间；

journald 默认将日志转发给 rsyslog，这会导致日志写了多份，/var/log/messages 中包含了太多无关日志，不方便后续查看，同时也影响系统性能。

``` bash
mkdir /var/log/journal # 持久化保存日志的目录
mkdir /etc/systemd/journald.conf.d
cat > /etc/systemd/journald.conf.d/99-prophet.conf <<EOF
[Journal]
# 持久化保存到磁盘
Storage=persistent

# 压缩历史日志
Compress=yes

SyncIntervalSec=5m
RateLimitInterval=30s
RateLimitBurst=1000

# 最大占用空间 10G
SystemMaxUse=10G

# 单日志文件最大 200M
SystemMaxFileSize=200M

# 日志保存时间 2 周
MaxRetentionSec=2week

# 不将日志转发到 syslog
ForwardToSyslog=no
EOF
systemctl restart systemd-journald
```

### 升级内核

``` bash
sudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
# 安装完成后检查 /boot/grub2/grub.cfg 中对应内核 menuentry 中是否包含 initrd16 配置，如果没有，再安装一次！
sudo yum --enablerepo=elrepo-kernel install -y kernel-lt
# 设置开机从新内核启动
grub2-set-default 0
```

安装内核源文件（可选，在升级完内核并重启机器后执行）:
``` bash
# sudo yum erase kernel-headers
sudo yum --enablerepo=elrepo-kernel install kernel-lt-devel-$(uname -r) kernel-lt-headers-$(uname -r)
```

### 关闭 NUMA

``` bash
sudo cp /etc/default/grub{,.bak}
sudo vim /etc/default/grub # 在 GRUB_CMDLINE_LINUX 一行添加 `numa=off` 参数，如下所示：
sudo diff /etc/default/grub.bak /etc/default/grub
6c6
< GRUB_CMDLINE_LINUX="crashkernel=auto rd.lvm.lv=centos/root rhgb quiet"
---
> GRUB_CMDLINE_LINUX="crashkernel=auto rd.lvm.lv=centos/root rhgb quiet numa=off"
```

重新生成 grub2 配置文件：

``` bash
sudo cp /boot/grub2/grub.cfg{,.bak}
sudo grub2-mkconfig -o /boot/grub2/grub.cfg
```

### 检查系统内核和模块是否适合运行 docker (仅适用于 linux 系统)

``` bash
curl https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh > check-config.sh
bash ./check-config.sh
```

## 参考：
1. 系统内核相关参数参考：https://docs.openshift.com/enterprise/3.2/admin_guide/overcommit.html
